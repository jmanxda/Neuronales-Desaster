% !TEX root = 00_arbeit.tex

%---------------------------------------------------------------------------------
%% Stata

\section{Analyse der Prognosefähigkeit}\label{sec:analyse}

Aufgrund der in \autoref{sec:vergleich_la} festgestellten Einflüsse auf die Vorhersagegenauigkeit eines Netzwerkes werden in diesem Abschnitt diese Faktoren variiert, um festzustellen welche Faktoren und dessen Werte zu einem Netzwerk mit geringster Prognoseabweichung führen.

%In diesem Abschnitt erfolgt die Analyse der Prognosefähigkeit eines MLP-Netzwerkes. Hierbei werden die in \autoref{sec:algorithm} hergeleiteten Algorithmen einem Vergleich unterzogen.


\subsection{Vorbereitung der Messungen}

Die von der Netztopologie bedingten Faktoren sind die Aktivierungsfunktion, die An- bzw. Abwesenheit des Bias-Neurons und der Lernalgorythmus. Zusätzlich spielen bei dem Lernalgorythmus die jeweiligen Parameter eine Rolle dessen optimale Werte bestimmt werden müssen, bevor die Prognosefähigkeit des Netzes bewertet werden kann.
Im Folgenden wird der Einfluss dieser Faktoren auf die Vorhersagegenauigkeit untersucht. Zum Einsatz kommt hierfür ein dreischichtiges MLP, welches in \autoref{fig:MLP-Algorithm} dargestellt ist. Wie in \autoref{sec:vergleich_la} erklärt wird die Anzahl der Eingabeneuronen durch die Anzahl an Variablen bestimmt. Die in dieser Arbeit verwendeten Variablen werden in \autoref{sec:datensatz} näher beschrieben. Die optimale Anzahl der verdeckten Neuronen wird iterativ bestimmt und da der Strompereis prognostiziert werden soll gibt es ein Ausgabeneuron. 

Als Aktivierungsfunktion werden die logistische Funktion und der Tangens-Hyperbolicus untersucht. Da der Wertebereich der logistischen Funktion [0,1] und der Wertebereich des Tangens-Hyperbolicus [-1,1] beträgt werden alle Variablen des Datensatzes auf diese Wertebereiche angepasst. Zu diesem Zweck wird die Min-Max bzw. die lineare Normalisierung
\begin{equation}
x_i'=(max_{Ziel} - min_{Ziel}) \cdot \left ( \frac{x_i-min_{Daten}}{max_{Daten}-min_{Daten}} \right ) + min_{Ziel}
\label{gl:norm}
\end{equation}
mit $x_i$ als Ausgangswert, $x_i'$ als normalisierter Wert, $max_{Ziel}$/$min_{Ziel}$ als Maximal-/Minimalwert des gewünschten Wertebereiches und $max_{Daten}$/$min_{Daten}$ als Maximal-/Minimalwert der Variable im betrachteten Zeitraum durchgeführt. Der Vorteil dieses Normalisierungsverfahrens liegt darin, dass die Proportionen der Daten im neuen Wertebereich erhalten bleiben. Somit bleiben auch die Abhängigkeiten und Beziehungen zwischen den Variablen erhalten.\,\citef[16]{neuralnet_intro} 

Betrachtet man die logistische Funktion so werden die Werte Null bzw. Eins asymptotisch in der Unendlichkeit erreicht. Somit lernt das Netzwerk bei der Eingabe der beiden Werte nur sehr langsam.\,\citef[158]{Rashid2016} Aus diesem Grund wird der Datensatz auf den Wertebereich [0.1,0.9] geändert. Die gleiche Begründung führt beim Tangens-Hyperbolicus zu einem Wertebereich von [-0.9,0.9].

Um die Einflüsse der in \autoref{sec:vergleich_la} besprochenen \glqq schlechten\grqq~Minima zu reduzieren werden in dieser Arbeit 20 Neuinitialisierungen durchgeführt, um die optimalen Parameter zu finden.

Mit der Variation des Lernalgorythmus, der Aktivierungsfunktion und der An- und Abwesenheit des Bias-Neurons ergeben sich acht Variationsmöglichkeiten bei denen zunächst, aus der Begründung aus \autoref{sec:eval_maße} folgernd, mit Hilfe des $RMSE$ die optimalen Netzparameter bestimmt werden. Das Optimum eines Parameters ist erreicht wenn die Abweichung zwischen vorhergesagtem und tatsächlichen Preis am geringsten ist und somit den niedrigsten $RMSE$ aufweist. Anschließend wird die Vorhersagegenauigkeit eines jeden Lernalgorithmus mit den jeweiligen optimalen Parametern, wie in \autoref{sec:eval_maße} erleutert, mit Hilfe des $RMSE$, $MAE$, $ABS$, $REL$, $R^2$, $RAE$, $MAPE_2$, $sMAPE$, $EV$ und des $U2$ ausgewertet.

\subsection{Erklärung des Datensatzes}\label{sec:datensatz}

Untersucht werden sollen beide Lernalgorithmen auf die Lerngeschwindigkeit und das Vorhersagevermögen. Hierzu werden die in \autoref{sec:algorithm} vorgestellten Algorithmen in Stata implementiert und mit Hilfe des in \autoref{tab:datensatz} dargestellten Datensatzes untersucht.

\begin{filecontents*}{datensatz.tex}
{\setstretch{1.0}
\captionsetup{skip=1pt,margin=5pt,position=below} %skip=1pt,
\rowcolors{3}{tableShade}{white}

\begin{longtable}{Zrccl}
    \caption{\farbig{Datensatz}} \label{tab:datensatz}\\
    \toprule
    \hiderowcolors

        Variable                         & Einheit    & Minimalwert   & Maximalwert   & Quelle            \\
    \midrule
    \endfirsthead
        \multicolumn{5}{c}{\footnotesize \tablename\ \thetable{}: Fortsetzung der vorherigen Seite} \\
    \toprule
        %\multicolumn{1}{l}{\textbf{Verweis}} & \multicolumn{1}{Z}{\textbf{Modell}} & \multicolumn{1}{Z}{\textbf{Lernalgorythmus}} & \multicolumn{1}{Z}{\textbf{Markt}} & \multicolumn{1}{Z}{\textbf{Performancemaß}} \\
        Variable                         & Einheit    & Minimalwert   & Maximalwert   & Quelle            \\

    \midrule
    \endhead
    \midrule
        \multicolumn{5}{c}{{\footnotesize \tablename\ \thetable{}: Fortsetzung auf der nächsten Seite}} \\
    \bottomrule
    \endfoot
    \bottomrule
        \caption*{\footnotesize $^*$\,Internetseiten der Übertragungsbetreiber: Amprion, Tennet, 50Hertz, TransnetBW. Werte wurden aufsummiert. $^\dagger$\,Der Preis wurde von US-Dollar in Euro umgerechnet, fehlende Daten extra- bzw. interpoliert und der Tagespreis wurde für jede Stunde als konstant angenommen. }
        %\multicolumn{5}{c}{\footnotesize $^*$\,Internetseiten der Übertragungsbetreiber: Amprion, Tennet, 50Hertz, TransBW. Werte wurden aufsummiert. \farbig{\footnotesize Abkürzungen ausschreiben}}
        
    \endlastfoot
    \showrowcolors
        Strompreis                      & [€/MWh]       & $-221,99$ & $210$         & EEX.com           \\
        Erzeugte Energie aus Wind/Sonne & [MWh]         & $263,35$  & $44606,29$    & $^*$              \\
        Energieverbrauch                & [MWh]         & $29201$   & $79884$       & Entsoe.net        \\
        Kosten für CO$_2$               & [€/Tonne]     & $2,68$    & $16,84$       & EEX.com           \\
        Erdgaspreis                     & [€/MWh]       & $11,24$   & $29,06$       & Thomson Reuters   \\
        Kohlepreis$^\dagger$            & [€/Tonne]     & $47,995$  & $190,414$     & EEX.com           \\
        Heizölpreis$^\dagger$           & [€/Gallone]   & $0,941$   & $4,867$       & Thomson Reuters   \\
        Uranpreis$^\dagger$             & [€/kg]        & $81,028$  & $232,458$     & Thomson Reuters   \\
        Stunde des Tages                & [h]           & $1$       & $24$          & -                 \\
        Tag der Woche                   & [d]           & So:\,$0$  & Sa:\,$6$      & -                 \\
        
\end{longtable}

}
\end{filecontents*}
\LTXtable{\textwidth}{datensatz}

Der Datensatz besteht aus einer Zeitreihe der in \autoref{tab:datensatz} dargestellten Variablen. Dabei ist in der ersten Spalte die Variable des Datensatzes, nachfolgend die Einheiten, in den nächsten beiden Spalten der Minimal- und Maximalwert der Variable im betrachteten Zeitraum und in der Letzten Spalte die Herkunft der Information dargestellt. Der betrachtete Zeitraum erstreckt sich vom 01.04.2010 bis zum 27.08.2016. Der Strompreis ist für jede Stunde eines jeden Tages angegeben und beinhaltet somit 56180 Datenpunkte. Nicht jede Variable des Datensatzes besitzt in seiner ursprünglichen Form 24 Werte für einen Tag. In diesen Fällen werden die fehlenden Daten entweder extra- bzw. interpoliert, um die Anzahl der Daten an den Strompreis anzupassen. Außerdem werden die Variablen an die selbe Währung angepasst. Für diesen Zweck wird der Tägliche US-Dollar/Euro Wechselkurs genutzt, um den Kohlepreis von \$/Tonne, den Heizölpreis von \$/Gallone und den Uranpreis von \$/kg respektive in €/Tonne, €/Gallone und €/kg umzurechnen.

Um das Vorhersagevermögen eines Netzes untersuchen zu können wird der Datensatz bestehend aus 56180 Datenpunkten pro Variable in zwei Sets unterteilt. Das Trainingsset beinhaltet 46180 Datenpunkte und das Testset besteht aus 10000 Datenpunkten. Diese Unterteilung ist notwendig, um die Netzwerke out-of-sample\,\footnote{Dies ist ein aus dem englischen ins deutsche übernommener Begriff und beteutet, dass das zu testende Modell mit Daten getestet wird welche es während dem Training nicht \glqq gesehen\grqq~hat. Bei guten Ergebnissen beweist das Modell damit seine Generalisierungsfähigkeit.} untersuchen zu können und so dem in \autoref{sec:vergleich_la} besprochenen \glqq Auswendiglernen\grqq~vorzubeugen. Somit wird ein Netzwerk nach dem Training danach bewertet wie es die Strompreise der nächsten 10000 Stunden vorhersagen kann.

\begin{figure}[!htb]
    \centering
        \input{Bilder/Plot/misc/autocorrelation.tex}
    \caption{Autocorrelation der stündlichen Elektrizitätspreise.}
    \label{fig:autocorrelation}
\end{figure}
\todo{autocorellations untersuchung und warum der 24. Wert}


\subsection{Auswertung Backpropagation}\label{sec:aus_backprop}

Bei dem klassischen Backpropagation-Verfahren, welches in \autoref{sec:Backpropagation} vorgestellt wird, wird zunächst die optimale Lernrate $\alpha$ bestimmt. Anschließend wird die passende Anzahl an verdeckten Neuronen ermittelt und schließlich wird die vertretbare Anzahl an Epochen festgelegt.

Hierzu wird in \autoref{fig:BP_logist_o_lrate} zunächst anhand eines MLP mit logistischer Aktivierungsfunktion und ohne Bias-Neuron beispielhaft gezeigt wie die optimale Lernrate in dieser Arbeit ermittelt wird. Zunächst wird die Anzahl der verdeckten Neuronen im einstelligen Bereich eingestellt. In diesem Falle sind es 5 verdeckte Neuronen gewesen. Als nächstes wird die Lernrate von Null bis Eins in einer Schrittweite von 0,001 erhöht und das Netzwerk wird bei jedem Schritt 20 Mal neu initialisiert, trainiert und mit dem Testset getestet. So entstehen 20 $RMSE$-Werte die anschließend gemittelt werden und in \autoref{fig:BP_logist_o_lrate} im oberen Graphen aufgetragen werden. Dieser weist gerade zu Beginn zwar ein Minimum auf aber durch die Sprunghaften Änderungen, die auf \glqq schlechte\grqq~Minima der Fehlerlandschaft zurückzuführen sind, erweist sich die Bestimmung des $RMSE$-Minimums mit dem bloßen Auge als problematisch. Durch den konkaven Verlauf des Grafen hat auch das Fitten der Daten mit den standard Funktionen in OriginLab zu keinem zufriedenstellenden Ergebniss geführt.

\begin{figure}[!htb]
    \centering
        \input{Bilder/Plot/BP/BP_logis_o_lrate.tex}
    \caption{Bestimmung der Lernrate $\alpha$ mit dem geringsten Fehler bei einem MLP ohne Bias-Neuron welches mit dem Backpropagation-Verfahren trainiert wird. \farbig{das ist noch nicht fertig} }
    \label{fig:BP_logist_o_lrate}
\end{figure}

Aus diesem Grund wird nochmals eine höher auflösende Messung im Bereich von Null und 0,2 mit einer Schrittweite von 0,0002 durchgeführt, die in \autoref{fig:BP_logist_o_lrate} unten dargestellt ist. Der sich so ergebende Verlauf lässt sich durch eine schiefe Asymptote annähern. Durch die erste Ableitung der angenäherten Funktion lässt sich auch das $RMSE$-Minimum bei einer Lernrate von 0,025 bestimmen.\\


\begin{figure}[!htb]
    \centering
        \input{Bilder/Plot/BP/BP_logis_o_hneuron.tex}
    \caption{Bestimmung der Anzahl an verdeckten Neuronen mit dem geringsten Fehler bei einem MLP ohne Bias-Neuron. Der Graph zeigt pro Datenpunkt den Mittelwert aus 20 Einzelmessungen.}
    \label{fig:BP_logist_o_hneuron}
\end{figure}

Im nächsten Schritt wird die Anzahl der verdeckten Neuronen ermittelt. Dabei wird die Lernrate auf den zuvor bestimmten Wert eingestellt und die Anzahl der verdeckten Neuronen von Eins an, um ein Neuron erhöht. Die Grenze hierbei wird nur durch die Rechenkapazität des Computers bestimmt auf dem das Netzwerk berechnet wird. Wie aber in \autoref{BP_logist_o_hneuron} festgestellt tendiert ein Netzwerk mit steigender Anzahl an verdeckten Neuronen zum Auswendiglernen der Daten. Daher ist eine niedrige Anzahl zu bevorzugen. In dem gleichen Netzwerk wie vorher die Lernrate bestimmt wird kann der $RMSE$-Verlauf in Abhängigkeit der Anzahl verdeckter Neuronen in \autoref{fig:BP_logist_o_hneuron} eingesehen werden. Der niedrigste $RMSE$-Wert wird hier bei Drei verdeckten Neuronen gemessen.\\ 

\begin{figure}[!htb]
    \centering
        \input{Bilder/Plot/BP/BP_logis_o_epochen.tex}
    \caption{Bestimmung der der Anzahl an vertretbarer Epochen. Wobei die graue Fläche den jeweiligen Maximal- bzw. Minimalwert einer Messung und der schwarze Graph den Mittelwert darstellt.}
    \label{fig:BP_logis_o_epochen}
\end{figure}

Schließlich wird die Anzahl der Epochen bestimmt in dem die Lernrate auf 0,025 und die Anzahl an verdeckten Neuronen auf Drei gesetzt wird und die Epochenanzahl von Eins an erhöht wird. Das Ergebniss dieser Messung ist in \autoref{fig:BP_logis_o_epochen} dargestellt. Hierbei gibt die graue Fläche den jeweiligen Maximal- bzw. Minimalwert einer Messung an und der schwarze Verlauf den Mittelwert. Gerade an dem Maximalwert lässt sich erkennen, dass die Höhe der Fehler mit steigender Epochenanzahl geringer wird und ab 30 Epochen auch die Höhe der Ausreißer sprunghaft abnimmt. Wohingegen der Minimalwert sich durchgehend zwischen Acht und Neun bewegt. Daraus kann geschlossen werden, dass mit steigender Anzahl an Epochen die Wahrscheinlichkeit steigt bessere Minima zu erreichen oder das Netzwerk anfängt die Daten auswendig zu lernen. Dies wurde zwar versucht durch den geteilten Datensatz zu vermeiden dennoch wird in der Literatur\,\citef[60]{dkriesel07} darauf hingewiesen, dass in wenn das Testset dazu benutzt wird, um die optimalen Parameter eines Netzwerkes zu bestimmen das Netztzwerk so auch auf die Testdaten zugeschnitten wird. Um hier Abhilfe zu schaffen wird empfohlen ein drittes Validierungsset zu erstellen\,\citef[44]{neuralnet_intro} welches nur der Evaluation des Netzes dient oder man wählt bewusst eine geringere Anzahl an Epochen. In dieser Arbeit wird die letztere Methode gewählt. Somit wird für das MLP mit logistischer Aktivierungsfunktion und ohne Bias-Neuron eine Epochenanzahl von 30 gewählt. Da ab diesem Wert eine deutliche Veränderung des $RMSE$-Verlaufes zu beobachten ist.

Bei der Bestimmung der optimalen Parameter der Netzwerke welche sich in der Aktivierungsfunktion und dem Vorhandensein eines Bias-Neurons unterscheiden wird analog vorgegangen. 


\begin{filecontents*}{BP_resultat.tex}
{\setstretch{1.0}
\captionsetup{skip=1pt,margin=5pt,position=below} %skip=1pt,
\rowcolors{3}{tableShade}{white}

\begin{longtable}{cccccccc}
    \caption{\farbig{BP resultat}} \label{tab:BP_resultat}\\
    \toprule
    \hiderowcolors

       \multicolumn{1}{Y}{Aktivierungs funktion} &      \multicolumn{1}{Y}{Bias- Neuron} &   \multicolumn{1}{Y}{Lern- rate} &  \multicolumn{1}{Y}{verd. Neuronen} &  \multicolumn{1}{Y}{Epochen} &  \multicolumn{1}{Y}{Trainings zeit} & \multicolumn{1}{Y}{min RMSE}  & \multicolumn{1}{Y}{Berechnungs zeit} \\

    \midrule
    \endfirsthead
        \multicolumn{8}{c}{\footnotesize \tablename\ \thetable{}: Fortsetzung der vorherigen Seite} \\
    \toprule
        %\multicolumn{1}{l}{\textbf{Verweis}} & \multicolumn{1}{Z}{\textbf{Modell}} & \multicolumn{1}{Z}{\textbf{Lernalgorythmus}} & \multicolumn{1}{Z}{\textbf{Markt}} & \multicolumn{1}{Z}{\textbf{Performancemaß}} \\
       % Aktivierungsfunktion &      Bias-Neuron &   Lernrate &  verdeckte Neuronen &  Epochen &  Trainingszeit &  min RMSE  & Berechnungszeit \\
    \midrule
    \endhead
    \midrule
        \multicolumn{8}{c}{{\footnotesize \tablename\ \thetable{}: Fortsetzung auf der nächsten Seite}} \\
    \bottomrule
    \endfoot
    \bottomrule
        %\caption*{\footnotesize $^*$\,Internetseiten der Übertragungsbetreiber: Amprion, Tennet, 50Hertz, TransnetBW. Werte wurden aufsummiert. $^\dagger$\,Der Preis wurde von US-Dollar in Euro umgerechnet, fehlende Daten extra- bzw. interpoliert und der Tagespreis wurde für jede Stunde als konstant angenommen. }

        
    \endlastfoot
    \showrowcolors
        logist.                 & o       & $0,025$ & $3$         & 30  & $7$h:$44$m:$39$s & $8,31$ & $10$s         \\
        logist.                 & m       & $0,016$ & $3$         & 33  & $8$h:$44$m:$11$s & $8,95$ & $15$s         \\
        Tanh.                   & o       & $0,81$  & $5$         & 30  & $6$h:$46$m:$50$s & $9,24$ & $14$s         \\
        Tanh.                   & m       & $0,83$  & $5$         & 27  & $8$h:$29$m:$29$s & $9,83$ & $16$s         \\

        
\end{longtable}

}
\end{filecontents*}
\LTXtable{\textwidth}{BP_resultat}


\begin{figure}[!htb]
    \centering
        %\input{Bilder/Plot/BP/BP_logis_o_result.tex}
    \caption{\farbig{Beschreibung erstellen}}
    \label{fig:BP_logis_o_result}
\end{figure}

